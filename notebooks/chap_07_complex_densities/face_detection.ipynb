{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import astuple\n",
    "import os\n",
    "from pathlib import Path \n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "sys.path.insert(0, str(Path().absolute().parents[1]))\n",
    "\n",
    "from experiments.datasets.faces import FaceImage, FaceAnnotation\n",
    "from cv_prince.chap_07_complex_densities.gmm import ExpectationMaximisationGMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_dir = os.environ.get(\"DATASETS\")\n",
    "data_dir = Path(root_data_dir) / \"FDDB\"\n",
    "faces_dir = data_dir / \"originalPics\"\n",
    "fold_dir = data_dir / \"FDDB-folds\"\n",
    "\n",
    "fold_id = 1\n",
    "\n",
    "fold_file = fold_dir / f\"FDDB-fold-{fold_id:02d}.txt\"\n",
    "fold_ellipse_file = fold_dir / f\"FDDB-fold-{fold_id:02d}-ellipseList.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat(Path(root_data_dir)/'face_cv_prince/FaceNonFace.mat')\n",
    "plt.imshow(mat[\"face\"][..., 700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fold = 10\n",
    "val_folds = [8, 9]\n",
    "train_folds = [1, 2, 3, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_images_per_folds: dict[int, list[FaceImage]] = {}\n",
    "\n",
    "for fold_ellipse_file in sorted(fold_dir.glob(\"FDDB-fold-*\")):\n",
    "    if not fold_ellipse_file.name.endswith(\"ellipseList.txt\"):\n",
    "        continue\n",
    "\n",
    "    fold_id = int(fold_ellipse_file.name.split(\"-\")[-2])\n",
    "    face_images: list[FaceImage] = []\n",
    "\n",
    "    with open(fold_ellipse_file, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            \n",
    "            if not line:\n",
    "                break\n",
    "\n",
    "            if line.endswith(\"\\n\"):\n",
    "                line = line[:-1]\n",
    "\n",
    "            assert line.startswith(\"2002\") or line.startswith(\"2003\")\n",
    "            \n",
    "            face_img_path = faces_dir / (line + \".jpg\")\n",
    "            num_faces = int(fid.readline())\n",
    "            face_image = FaceImage(file_path=face_img_path, num_faces=num_faces)\n",
    "            \n",
    "            for _ in range(num_faces):\n",
    "                face_anno = FaceAnnotation.from_str(fid.readline())\n",
    "                face_image.add_face(face_anno)\n",
    "\n",
    "            face_images.append(face_image)\n",
    "    \n",
    "    face_images_per_folds[fold_id] = face_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_faces = []\n",
    "train_non_faces = []\n",
    "data_size = (24, 24)\n",
    "\n",
    "for fold_id in train_folds:\n",
    "    face_images = face_images_per_folds[fold_id]\n",
    "\n",
    "    for face_image in face_images:\n",
    "\n",
    "        if len(train_faces) < 1000:\n",
    "            tallest_face = face_image.get_tallest_face()\n",
    "\n",
    "            cropped_face = face_image.crop_face_img(tallest_face)\n",
    "            cropped_face = cropped_face.convert(\"L\")\n",
    "            cropped_face = cropped_face.resize(data_size)\n",
    "            train_faces.append(np.asarray(cropped_face))\n",
    "\n",
    "        if len(train_non_faces) < 1000:\n",
    "            try:\n",
    "                non_face = face_image.crop_non_face_img(\n",
    "                    seed=12345, max_overlap=0.15, num_instances=1, max_trials=100\n",
    "                )[0]\n",
    "            except IndexError:\n",
    "                continue\n",
    "\n",
    "            non_face = non_face.convert(\"L\")\n",
    "            non_face = non_face.resize(data_size)\n",
    "            train_non_faces.append(np.asarray(non_face))\n",
    "\n",
    "print(len(train_faces))\n",
    "print(len(train_non_faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_faces[30], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_faces_arr = np.stack(train_faces, axis=0)\n",
    "train_faces_arr = np.reshape(train_faces_arr, (train_faces_arr.shape[0], -1))\n",
    "train_faces_arr = train_faces_arr.astype(np.float64)\n",
    "train_faces_arr /= 255.0\n",
    "# face_means = np.mean(train_faces_arr, axis=0)\n",
    "# train_faces_arr -= face_means[np.newaxis, ...]\n",
    "print(train_faces_arr.shape)\n",
    "\n",
    "train_non_faces_arr = np.stack(train_non_faces, axis=0)\n",
    "train_non_faces_arr = np.reshape(train_non_faces_arr, (train_non_faces_arr.shape[0], -1))\n",
    "train_non_faces_arr = train_non_faces_arr.astype(np.float64)\n",
    "train_non_faces_arr /= 255.0\n",
    "# face_std = np.std(train_faces_arr, axis=0)\n",
    "# train_faces_arr /= face_std[np.newaxis, ...]\n",
    "print(train_non_faces_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = train_faces_arr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=12345)\n",
    "labels = kmeans.fit_predict(train_faces_arr)\n",
    "\n",
    "one_hot_encoding = np.zeros((num_samples, 10), dtype=bool)\n",
    "np.put_along_axis(one_hot_encoding, labels[:, None], 1, axis=1)\n",
    "\n",
    "weights = one_hot_encoding.sum(axis=0) / num_samples\n",
    "\n",
    "means = np.zeros(one_hot_encoding.shape + train_faces_arr.shape[-1:])\n",
    "means[one_hot_encoding, :] = train_faces_arr\n",
    "means = means.sum(axis=0)\n",
    "means /= one_hot_encoding.sum(axis=0)[:, None]\n",
    "\n",
    "covs = []\n",
    "\n",
    "eps = 10 * np.finfo(np.float64).eps\n",
    "diffs = train_faces_arr - means[labels, :]\n",
    "\n",
    "covs = np.stack(\n",
    "    [\n",
    "        diffs[labels==i].T @ diffs[labels==i] / (diffs[labels==i].shape[0] + eps)\n",
    "        for i in range(10)\n",
    "    ]\n",
    ")\n",
    "covs += 1e-6 * np.eye(covs.shape[-1])[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=10, random_state=12345, init_params=\"random_from_data\")\n",
    "gmm._initialize_parameters(train_faces_arr, random_state=np.random.RandomState(gmm.random_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_em_fitter = ExpectationMaximisationGMM(num_components=10, seed=12345)\n",
    "\n",
    "faces_em_fitter.initialise_params(train_faces_arr)\n",
    "faces_em_fitter.ndims = train_faces_arr.shape[1]\n",
    "faces_em_fitter.weights = gmm.weights_\n",
    "faces_em_fitter.means = gmm.means_\n",
    "faces_em_fitter.covs = gmm.covariances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_em_fitter.fit(train_faces_arr)\n",
    "scipy_prediction = gmm.fit_predict(train_faces_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 10, figsize=(15, 3))\n",
    "\n",
    "for i in range(10):\n",
    "    axes[0, i].imshow(gmm.means_[i, ...].reshape((24, 24)), cmap=\"gray\")\n",
    "    axes[1, i].imshow(faces_em_fitter.means[i, ...].reshape((24, 24)), cmap=\"gray\")\n",
    "\n",
    "    axes[0,i].set_title(f\"{gmm.weights_[i]:.3f}\")\n",
    "    axes[0,i].set_axis_off()\n",
    "    axes[1,i].set_title(f\"{faces_em_fitter.weights[i]:.3f}\")\n",
    "    axes[1,i].set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_with_most_faces = face_images[0]\n",
    "for face_image in face_images[1:]:\n",
    "    if face_image.num_faces > img_with_most_faces.num_faces:\n",
    "        img_with_most_faces = face_image\n",
    "\n",
    "k = 5\n",
    "img_with_k_faces = None\n",
    "for face_image in face_images:\n",
    "    if face_image.num_faces == k:\n",
    "        img_with_k_faces = face_image\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_image = img_with_most_faces\n",
    "img = face_image.show_annotated_image()\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.gca().set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_instances = None\n",
    "res = face_image.crop_non_face_img(\n",
    "    seed=12345, max_overlap=0.1, num_instances=num_instances\n",
    ")\n",
    "\n",
    "num_cols = 6\n",
    "num_rows = int(np.ceil(len(res) / num_cols))\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, num_rows * 10 / num_cols))\n",
    "\n",
    "for ax, non_face_img in zip(axes.flatten(), res):\n",
    "    ax.imshow(non_face_img)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "num_img_in_last_row = num_faces % num_cols\n",
    "if num_img_in_last_row > 0:\n",
    "    for i in range(num_cols-num_img_in_last_row):\n",
    "        fig.delaxes(axes.flat[-i-1])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_faces = face_image.num_faces\n",
    "\n",
    "num_rows = int(np.ceil(num_faces / num_cols))\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, num_rows * 10 / num_cols))\n",
    "\n",
    "for ax, cropped_face in zip(axes.flatten(), face_image.get_all_croped_faces()):\n",
    "    ax.imshow(cropped_face, cmap=\"gray\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_axis_off()\n",
    "\n",
    "num_img_in_last_row = num_faces % num_cols\n",
    "if num_img_in_last_row > 0:\n",
    "    for i in range(num_cols-num_img_in_last_row):\n",
    "        fig.delaxes(axes.flat[-i-1])\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-prince-YM7UBAsG-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
