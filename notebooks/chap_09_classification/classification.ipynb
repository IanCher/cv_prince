{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab4282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.inspection import DecisionBoundaryDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dc9890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(array: np.ndarray) -> np.ndarray:\n",
    "    sign = np.sign(array)\n",
    "    exp = np.exp(-sign * array)\n",
    "\n",
    "    num = np.where(sign < 0, exp, 1)\n",
    "    den = 1 + exp\n",
    "\n",
    "    return num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bda561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log1pexp(array: np.ndarray) -> np.ndarray:\n",
    "    thresh_1 = -37\n",
    "    thresh_2 = 18\n",
    "    thresh_3 = 34\n",
    "\n",
    "    lower_than_1 = (array <= thresh_1).astype(int)\n",
    "    lower_than_2 = (array <= thresh_2).astype(int)\n",
    "    lower_than_3 = (array <= thresh_3).astype(int)\n",
    "    lower = lower_than_1 + lower_than_2 + lower_than_3\n",
    "\n",
    "    res = np.empty_like(array)\n",
    "    res[lower==0] = array[lower==0]\n",
    "    res[lower==1] = array[lower==1] + np.exp(-array[lower==1])\n",
    "    res[lower==2] = np.log1p(np.exp(array[lower==2]))\n",
    "    res[lower==3] = np.exp(array[lower==3])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcd34c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "samples = iris.data[:, :2]  # we only take the first two features.\n",
    "gt_classes = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928c5167",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "for label in np.unique(gt_classes):\n",
    "    ax.scatter(\n",
    "        samples[gt_classes==label, 0], \n",
    "        samples[gt_classes==label, 1], \n",
    "        label=iris.target_names[label]\n",
    "    )\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd792c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver=\"newton-cg\")\n",
    "logreg.fit(samples, (gt_classes.copy() == 0).astype(int))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "DecisionBoundaryDisplay.from_estimator(\n",
    "    logreg,\n",
    "    samples,\n",
    "    cmap=plt.cm.Paired,\n",
    "    ax=ax,\n",
    "    response_method=\"predict\",\n",
    "    plot_method=\"pcolormesh\",\n",
    "    shading=\"auto\",\n",
    "    xlabel=\"Sepal length\",\n",
    "    ylabel=\"Sepal width\",\n",
    "    eps=0.5,\n",
    ")\n",
    "\n",
    "for label in np.unique(gt_classes):\n",
    "    ax.scatter(\n",
    "        samples[gt_classes==label, 0], \n",
    "        samples[gt_classes==label, 1], \n",
    "        label=iris.target_names[label]\n",
    "    )\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad35fe53",
   "metadata": {},
   "source": [
    "### Maximum Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d30993",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = samples.shape[0]\n",
    "X = np.concat([samples.T, np.ones((1, nsamples))], axis=0)\n",
    "W = gt_classes.copy() == 0\n",
    "W = W.astype(int)\n",
    "one_minus_W = 1 - W\n",
    "XXT = np.einsum(\"ij, kj -> ikj\", X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e33fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(phi: np.ndarray) -> np.ndarray:\n",
    "    phi_X = np.dot(phi, X)\n",
    "\n",
    "    sign = np.sign(phi_X)\n",
    "    exp = np.exp(-sign * phi_X)\n",
    "    log1pexp = np.log1p(exp)\n",
    "\n",
    "    obj = one_minus_W * phi_X\n",
    "    obj += np.where(sign >= 0, log1pexp, log1pexp - phi_X)\n",
    "\n",
    "    return np.sum(obj) / nsamples\n",
    "\n",
    "def objective_jac(phi: np.ndarray) -> np.ndarray:\n",
    "    sig_minus_W = sigmoid(np.dot(phi, X)) - W\n",
    "    return np.einsum(\"j, ij -> i\", sig_minus_W, X) / nsamples\n",
    "\n",
    "def objective_hess(phi: np.ndarray) -> np.ndarray:\n",
    "    sig_phi_X = sigmoid(np.dot(phi, X))\n",
    "    return np.einsum(\"k, ijk -> ij\", sig_phi_X * (1 - sig_phi_X), XXT) / nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b81d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results = minimize(\n",
    "    fun=objective,\n",
    "    x0=np.full((X.shape[0],), 0),\n",
    "    method=\"Newton-CG\",\n",
    "    jac=objective_jac,\n",
    "    hess=objective_hess,\n",
    "    options={\"maxiter\": 100},\n",
    ")\n",
    "print(opt_results)\n",
    "\n",
    "phi_opt = opt_results.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7d1255",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrange = np.array([0, 8])\n",
    "yrange = - (phi_opt[0] * xrange + phi_opt[2]) / phi_opt[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e929ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_x, grid_y = np.meshgrid(\n",
    "    np.linspace(xrange[0], xrange[1], 1000),\n",
    "    np.linspace(yrange[0], yrange[1], 1000),\n",
    "    indexing=\"xy\"\n",
    ")\n",
    "grid_coords = np.stack([grid_x, grid_y, np.ones_like(grid_x)], axis=-1)\n",
    "activations = grid_coords @ phi_opt\n",
    "likelihood_full = sigmoid(activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8748afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "ax.imshow(\n",
    "    likelihood_full,\n",
    "    cmap=\"hot\",\n",
    "    extent=[xrange[0], xrange[1], yrange[0], yrange[1]],\n",
    "    origin=\"lower\",\n",
    "    aspect=\"auto\",\n",
    ")\n",
    "for label in np.unique(gt_classes):\n",
    "    ax.scatter(\n",
    "        samples[gt_classes==label, 0], \n",
    "        samples[gt_classes==label, 1], \n",
    "        label=iris.target_names[label]\n",
    "    )\n",
    "ax.plot(xrange, yrange, \"g\")\n",
    "ax.set_xlim(samples[:, 0].min()-0.1, samples[:, 0].max()+0.1)\n",
    "ax.set_ylim(samples[:, 1].min()-0.1, samples[:, 1].max()+0.1)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadc0cbd",
   "metadata": {},
   "source": [
    "### Bayesian Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56bb6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([samples.T, np.ones((1, samples.shape[0]))], axis=0)\n",
    "W = gt_classes.copy() == 0\n",
    "W = W.astype(int)\n",
    "one_minus_W = 1 - W\n",
    "\n",
    "nsamples = X.shape[1]\n",
    "sigma_p = 1000\n",
    "\n",
    "XXT = np.einsum(\"kj, ij -> kij\", X, X)\n",
    "for i in range(nsamples):\n",
    "    assert np.allclose(X[:,i:i+1] @ X[:, i:i+1].T, XXT[..., i])\n",
    "    assert np.allclose(np.einsum(\"i, j -> ij\", X[:,i], X[:, i]), XXT[..., i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbc240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(phi: np.ndarray) -> np.ndarray:\n",
    "    obj_1 = 1.0 / (2 * sigma_p) * phi @ phi\n",
    "\n",
    "    activations = np.einsum(\"ij, i -> j\", X, phi)\n",
    "    obj_2 = np.logaddexp(0, -activations) + one_minus_W * activations\n",
    "\n",
    "    return obj_1 + obj_2.sum()\n",
    "\n",
    "def objective_jac(phi: np.ndarray) -> np.ndarray:\n",
    "    obj_1 = 1.0 / sigma_p * phi\n",
    "    \n",
    "    activations = np.einsum(\"ij, i -> j\", X, phi)\n",
    "    obj_2 = (sigmoid(activations) - W) * X \n",
    "\n",
    "    return obj_1 + np.sum(obj_2, axis=1)\n",
    "\n",
    "def objective_hess(phi: np.ndarray) -> np.ndarray:\n",
    "    obj_1 = 1 / sigma_p * np.eye(phi.shape[0])\n",
    "\n",
    "    activations = np.einsum(\"ij, i -> j\", X, phi)\n",
    "    proba = sigmoid(activations)\n",
    "    obj_2 = proba * (1 - proba) * XXT\n",
    "\n",
    "    return obj_1 + np.sum(obj_2, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159815b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace_mean = minimize(\n",
    "    objective,\n",
    "    np.zeros((X.shape[0],)),\n",
    "    method=\"Newton-CG\",\n",
    "    jac=objective_jac,\n",
    "    hess=objective_hess,\n",
    "    options={\"maxiter\": 100},\n",
    ").x\n",
    "\n",
    "laplace_cov = objective_hess(laplace_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dac7965",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrange = np.array([4, 8])\n",
    "yrange = np.array([1.9, 4.5])\n",
    "grid_x, grid_y = np.meshgrid(\n",
    "    np.linspace(xrange[0], xrange[1], 100),\n",
    "    np.linspace(yrange[0], yrange[1], 100),\n",
    "    indexing=\"xy\"\n",
    ")\n",
    "grid_coords = np.stack([grid_x, grid_y, np.ones_like(grid_x)], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae260baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace_means = np.einsum(\"ijk, k -> ij\", grid_coords, laplace_mean)\n",
    "laplace_covs = np.einsum(\"ijk, kl, ijl -> ij\", grid_coords, laplace_cov, grid_coords)\n",
    "laplace_log_factors = -0.5 * (np.log(2 * np.pi) + np.log(laplace_covs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ebdfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_gaussian(activation: float, i: int, j: int) -> np.ndarray:\n",
    "    diff = (activation - laplace_means[i, j]) ** 2\n",
    "    \n",
    "    return laplace_log_factors[i, j] - 0.5 * diff / laplace_covs[i, j]\n",
    "\n",
    "def gaussian(activation: float, i: int, j: int) -> np.ndarray:\n",
    "    return np.exp(log_gaussian(activation, i, j))\n",
    "\n",
    "def bernouilli(activation: float) -> float:\n",
    "    return sigmoid(activation)\n",
    "\n",
    "def joint_proba(activation: float, i: int, j: int) -> np.ndarray:\n",
    "    return bernouilli(activation) * gaussian(activation, i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979c3065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.integrate as integrate\n",
    "from itertools import product\n",
    "\n",
    "likelihood_full = np.empty_like(grid_x)\n",
    "for i, j in product(np.arange(grid_x.shape[0]), np.arange(grid_x.shape[1])):\n",
    "    likelihood_full[i, j] = integrate.quad(lambda x: joint_proba(x, i, j), -np.inf, np.inf)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc80fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood_approx = -np.logaddexp(\n",
    "    0, \n",
    "    -laplace_means / np.sqrt(1 + np.pi * laplace_covs / 8)\n",
    ")\n",
    "likelihood_approx = np.exp(log_likelihood_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43feb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "ax.imshow(\n",
    "    likelihood_full,\n",
    "    cmap=\"hot\",\n",
    "    extent=[xrange[0], xrange[1], yrange[0], yrange[1]],\n",
    "    origin=\"lower\",\n",
    "    aspect=\"auto\",\n",
    ")\n",
    "ax.contour(grid_x, grid_y, likelihood_full, levels=[0.5])\n",
    "for label in np.unique(gt_classes):\n",
    "    ax.scatter(\n",
    "        samples[gt_classes==label, 0], \n",
    "        samples[gt_classes==label, 1], \n",
    "        label=iris.target_names[label]\n",
    "    )\n",
    "ax.set_xlim(samples[:, 0].min()-0.1, samples[:, 0].max()+0.1)\n",
    "ax.set_ylim(samples[:, 1].min()-0.1, samples[:, 1].max()+0.1)\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-prince-YM7UBAsG-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
